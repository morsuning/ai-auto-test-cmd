// Package utils æä¾›äº†ä¸€ç³»åˆ—ç”¨äºæ•°æ®å¤„ç†å’Œæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆçš„å·¥å…·å‡½æ•°ã€‚
// åŒ…å«XMLè§£æã€JSONè§£æä»¥åŠåŸºäºåŸå§‹æ•°æ®ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„åŠŸèƒ½ã€‚
package utils

import (
	"bufio"
	"bytes"
	"crypto/rand"
	"encoding/csv"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"time"
)

// DifyChatflowRequest è¡¨ç¤ºå‘é€ç»™Dify Chatflow APIçš„è¯·æ±‚
type DifyChatflowRequest struct {
	Inputs         map[string]any `json:"inputs"`          // è¾“å…¥å‚æ•°
	Query          string         `json:"query"`           // ç”¨æˆ·è¾“å…¥/æé—®å†…å®¹
	ResponseMode   string         `json:"response_mode"`   // å“åº”æ¨¡å¼ï¼šstreaming æˆ– blocking
	User           string         `json:"user"`            // ç”¨æˆ·æ ‡è¯†
	ConversationID string         `json:"conversation_id"` // ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
}

// DifyStreamEvent è¡¨ç¤ºDifyæµå¼å“åº”äº‹ä»¶
type DifyStreamEvent struct {
	Event          string `json:"event"`
	TaskID         string `json:"task_id"`
	MessageID      string `json:"message_id"`
	ConversationID string `json:"conversation_id"`
	Answer         string `json:"answer"`          // messageäº‹ä»¶çš„æ–‡æœ¬å†…å®¹
	CreatedAt      int64  `json:"created_at"`      // åˆ›å»ºæ—¶é—´æˆ³
	Data           any    `json:"data"`            // å…¶ä»–äº‹ä»¶çš„æ•°æ®
	Metadata       any    `json:"metadata"`        // message_endäº‹ä»¶çš„å…ƒæ•°æ®
	WorkflowRunID  string `json:"workflow_run_id"` // workflowç›¸å…³äº‹ä»¶çš„ID
	Audio          string `json:"audio"`           // TTSéŸ³é¢‘æ•°æ®
	Status         int    `json:"status"`          // erroräº‹ä»¶çš„çŠ¶æ€ç 
	Code           string `json:"code"`            // erroräº‹ä»¶çš„é”™è¯¯ç 
	Message        string `json:"message"`         // erroräº‹ä»¶çš„é”™è¯¯æ¶ˆæ¯
}

// GenerateTestCasesWithDify ä½¿ç”¨Dify Chatflow APIç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
func GenerateTestCasesWithDify(apiKey, baseURL, query string, inputs map[string]any, format, outputFile string, debug bool) error {
	// æ„å»ºè¯·æ±‚URL - ä½¿ç”¨æ–°çš„chat-messagesç«¯ç‚¹
	chatflowURL := fmt.Sprintf("%s/chat-messages", strings.TrimSuffix(baseURL, "/"))

	// æ„å»ºè¯·æ±‚ä½“
	reqBody := DifyChatflowRequest{
		Query:        query,
		Inputs:       inputs,
		ResponseMode: "streaming",
		User:         generateUserID(),
	}

	// åºåˆ—åŒ–è¯·æ±‚ä½“
	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚ä½“å¤±è´¥: %v", err)
	}

	// åˆ›å»ºHTTPè¯·æ±‚
	req, err := http.NewRequest("POST", chatflowURL, bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err)
	}

	// è®¾ç½®è¯·æ±‚å¤´
	req.Header.Set("Authorization", "Bearer "+apiKey)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "text/event-stream")

	// Debugæ¨¡å¼ï¼šæ˜¾ç¤ºå®é™…çš„è¯·æ±‚ä¿¡æ¯
	if debug {
		fmt.Println("\nğŸ” ==================== DEBUG: HTTPè¯·æ±‚è¯¦æƒ… ====================")
		fmt.Printf("ğŸ“ è¯·æ±‚URL: %s\n", req.URL.String())
		fmt.Printf("ğŸ”§ è¯·æ±‚æ–¹æ³•: %s\n", req.Method)
		fmt.Println("\nğŸ“‹ è¯·æ±‚å¤´ (Headers):")
		for key, values := range req.Header {
			for _, value := range values {
				if key == "Authorization" {
					// å®‰å…¨é®ç›–APIå¯†é’¥
					fmt.Printf("   %s: Bearer %s\n", key, maskAPIKey(apiKey))
				} else {
					fmt.Printf("   %s: %s\n", key, value)
				}
			}
		}
		fmt.Println("\nğŸ“¦ è¯·æ±‚ä½“ (Request Body):")
		// æ ¼å¼åŒ–JSONè¾“å‡ºï¼Œä½¿å…¶æ›´æ˜“è¯»
		var prettyJSON bytes.Buffer
		if indentErr := json.Indent(&prettyJSON, jsonData, "", "  "); indentErr == nil {
			fmt.Printf("%s\n", prettyJSON.String())
		} else {
			fmt.Printf("%s\n", string(jsonData))
		}
		fmt.Println("ğŸ” ============================================================")
	}

	// å‘é€è¯·æ±‚
	client := &http.Client{Timeout: 300 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("å‘é€è¯·æ±‚å¤±è´¥: %v", err)
	}
	defer resp.Body.Close()

	// Debugæ¨¡å¼ï¼šæ˜¾ç¤ºå“åº”ä¿¡æ¯
	if debug {
		fmt.Println("\nğŸ” ==================== DEBUG: HTTPå“åº”è¯¦æƒ… ====================")
		fmt.Printf("ğŸ“Š å“åº”çŠ¶æ€ç : %d %s\n", resp.StatusCode, resp.Status)
		fmt.Println("\nğŸ“‹ å“åº”å¤´ (Response Headers):")
		for key, values := range resp.Header {
			for _, value := range values {
				fmt.Printf("   %s: %s\n", key, value)
			}
		}
		fmt.Println("ğŸ” ============================================================")
	}

	// æ£€æŸ¥å“åº”çŠ¶æ€
	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : %dï¼Œå“åº”: %s", resp.StatusCode, string(body))
	}

	// å¤„ç†æµå¼å“åº”
	return processStreamingResponse(resp.Body, format, outputFile, debug)
}

// processStreamingResponse å¤„ç†Dify APIçš„æµå¼å“åº”
func processStreamingResponse(body io.Reader, format, outputFile string, debug bool) error {
	scanner := bufio.NewScanner(body)
	var collectedText strings.Builder
	var errorMsg string

	fmt.Println("ğŸ“¡ å¼€å§‹æ¥æ”¶æµå¼æ•°æ®...")

	for scanner.Scan() {
		line := scanner.Text()
		// è·³è¿‡ç©ºè¡Œå’Œédataè¡Œ
		if !strings.HasPrefix(line, "data: ") {
			continue
		}
		// æå–JSONæ•°æ®
		jsonData := strings.TrimPrefix(line, "data: ")
		if jsonData == "" {
			continue
		}
		// è§£æäº‹ä»¶
		var event DifyStreamEvent
		if err := json.Unmarshal([]byte(jsonData), &event); err != nil {
			fmt.Printf("âš ï¸  è§£æäº‹ä»¶å¤±è´¥: %v\n", err)
			continue
		}
		// Debugæ¨¡å¼ï¼šæ˜¾ç¤ºåŸå§‹å“åº”æ•°æ®
		if debug {
			fmt.Printf("\nğŸ” [DEBUG] æ”¶åˆ°äº‹ä»¶: %s\n", event.Event)
			fmt.Printf("åŸå§‹æ•°æ®: %s\n", jsonData)
			fmt.Println("----------------------------------------")
		}
		// å¤„ç†ä¸åŒç±»å‹çš„äº‹ä»¶
		switch event.Event {
		case "message":
			// LLMè¿”å›æ–‡æœ¬å—äº‹ä»¶ï¼Œä»…å®æ—¶è¾“å‡ºï¼Œä¸æ”¶é›†æ–‡æœ¬ï¼ˆé¿å…é‡å¤æ”¶é›†ï¼‰
			if event.Answer != "" {
				fmt.Print(event.Answer) // å®æ—¶æµå¼è¾“å‡ºæ–‡æœ¬ç‰‡æ®µ
			}
			if debug {
				fmt.Printf("\nğŸ” [DEBUG] Message ID: %s, Conversation ID: %s\n", event.MessageID, event.ConversationID)
			}
		case "message_file":
			// æ–‡ä»¶äº‹ä»¶ï¼Œè¡¨ç¤ºæœ‰æ–°æ–‡ä»¶éœ€è¦å±•ç¤º
			if debug {
				fmt.Printf("\nğŸ” [DEBUG] æ”¶åˆ°æ–‡ä»¶äº‹ä»¶\n")
				if event.Data != nil {
					if dataBytes, err := json.Marshal(event.Data); err == nil {
						fmt.Printf("æ–‡ä»¶æ•°æ®: %s\n", string(dataBytes))
					}
				}
			}
		case "message_end":
			// æ¶ˆæ¯ç»“æŸäº‹ä»¶ï¼Œæ”¶åˆ°æ­¤äº‹ä»¶åˆ™ä»£è¡¨æµå¼è¿”å›ç»“æŸ
			fmt.Println("\n\nâœ… æ¶ˆæ¯æ¥æ”¶å®Œæˆ!")
			if debug {
				fmt.Printf("ğŸ” [DEBUG] Message ID: %s, Conversation ID: %s\n", event.MessageID, event.ConversationID)
				if event.Metadata != nil {
					if metadataBytes, err := json.Marshal(event.Metadata); err == nil {
						fmt.Printf("å…ƒæ•°æ®: %s\n", string(metadataBytes))
					}
				}
			}
		case "message_replace":
			// æ¶ˆæ¯å†…å®¹æ›¿æ¢äº‹ä»¶
			if event.Answer != "" {
				fmt.Printf("\nğŸ”„ æ¶ˆæ¯å†…å®¹è¢«æ›¿æ¢: %s\n", event.Answer)
				collectedText.Reset() // æ¸…ç©ºä¹‹å‰æ”¶é›†çš„æ–‡æœ¬
				collectedText.WriteString(event.Answer)
			}
		case "workflow_started":
			// Workflowå¼€å§‹æ‰§è¡Œ
			fmt.Println("ğŸš€ Workflowå¼€å§‹æ‰§è¡Œ...")
			if debug {
				fmt.Printf("ğŸ” [DEBUG] Workflow Run ID: %s\n", event.WorkflowRunID)
				if event.Data != nil {
					if dataBytes, err := json.Marshal(event.Data); err == nil {
						fmt.Printf("Workflowæ•°æ®: %s\n", string(dataBytes))
					}
				}
			}
		case "node_started":
			// èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
			if nodeData, ok := event.Data.(map[string]any); ok {
				if debug {
					if title, exists := nodeData["title"]; exists {
						fmt.Printf("ğŸ”§ èŠ‚ç‚¹å¼€å§‹: %v\n", title)
					}
					if inputs, exists := nodeData["inputs"]; exists {
						fmt.Printf("ğŸ”§ èŠ‚ç‚¹è¾“å…¥: %v\n", inputs)
					}
				}
			}
		case "node_finished":
			// èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ
			if nodeData, ok := event.Data.(map[string]any); ok {
				if debug {
					if status, statusExists := nodeData["status"]; statusExists {
						if status == "succeeded" {
							fmt.Printf("âœ… èŠ‚ç‚¹å®Œæˆ: %v\n", nodeData["title"])
						} else {
							fmt.Printf("âŒ èŠ‚ç‚¹å¤±è´¥: %v\n", nodeData["error"])
						}
					}
					if outputs, exists := nodeData["outputs"]; exists {
						fmt.Printf("ğŸ”§ èŠ‚ç‚¹è¾“å‡º: %v\n", outputs)
					}
				}
			}
		case "workflow_finished":
			// Workflowæ‰§è¡Œç»“æŸ
			if workflowData, ok := event.Data.(map[string]any); ok {
				if debug {
					if dataBytes, err := json.Marshal(workflowData); err == nil {
						fmt.Printf("\nğŸ” [DEBUG] workflow_finishedå®Œæ•´æ•°æ®: %s\n", string(dataBytes))
					}
				}

				if status, exists := workflowData["status"]; exists {
					if status == "succeeded" {
						fmt.Println("\nğŸ‰ Workflowæ‰§è¡ŒæˆåŠŸ!")
					} else {
						fmt.Printf("\nâŒ Workflowæ‰§è¡Œå¤±è´¥: %s\n", status)
						if errorField, exists := workflowData["error"]; exists && errorField != nil {
							errorMsg = errorField.(string)
							fmt.Printf("é”™è¯¯ä¿¡æ¯: %s\n", errorMsg)
						}
					}
				}

				// æ£€æŸ¥outputså­—æ®µæ˜¯å¦åŒ…å«ç»“æœ
				if outputs, exists := workflowData["outputs"]; exists {
					if outputsMap, ok := outputs.(map[string]any); ok {
						// å°è¯•ä»outputsä¸­æå–æ–‡æœ¬å†…å®¹
						for _, value := range outputsMap {
							if valueStr, ok := value.(string); ok {
								// fmt.Printf("\n[è¾“å‡º] %s: \n---\n%s\n---", "æœ€ç»ˆç»“æœ", valueStr)
								// åªæœ‰å½“collectedTextä¸ºç©ºæ—¶æ‰æ”¶é›†æ–‡æœ¬ï¼Œé¿å…é‡å¤æ”¶é›†
								if collectedText.Len() == 0 {
									collectedText.WriteString(valueStr)
								}
							}
						}
					}
				}
			}
		case "tts_message":
			// TTSéŸ³é¢‘æµäº‹ä»¶
			if debug {
				fmt.Printf("\nğŸ” [DEBUG] æ”¶åˆ°TTSéŸ³é¢‘æ•°æ®ï¼Œé•¿åº¦: %d\n", len(event.Audio))
				fmt.Printf("Message ID: %s, Task ID: %s\n", event.MessageID, event.TaskID)
			}
		case "tts_message_end":
			// TTSéŸ³é¢‘æµç»“æŸäº‹ä»¶
			if debug {
				fmt.Printf("\nğŸ” [DEBUG] TTSéŸ³é¢‘æµç»“æŸ\n")
				fmt.Printf("Message ID: %s, Task ID: %s\n", event.MessageID, event.TaskID)
			}
		case "error":
			// æµå¼è¾“å‡ºè¿‡ç¨‹ä¸­å‡ºç°çš„å¼‚å¸¸
			fmt.Printf("\nâŒ æµå¼å“åº”é”™è¯¯: [%d] %s - %s\n", event.Status, event.Code, event.Message)
			return fmt.Errorf("APIè¿”å›é”™è¯¯: [%d] %s - %s", event.Status, event.Code, event.Message)
		case "ping":
			// æ¯10sä¸€æ¬¡çš„pingäº‹ä»¶ï¼Œä¿æŒè¿æ¥å­˜æ´»
			if debug {
				fmt.Printf("\nğŸ” [DEBUG] æ”¶åˆ°pingäº‹ä»¶ï¼Œä¿æŒè¿æ¥å­˜æ´»\n")
			}
		default:
			// Debugæ¨¡å¼ï¼šè¾“å‡ºæœªå¤„ç†çš„äº‹ä»¶ç±»å‹
			if debug {
				fmt.Printf("\nğŸ” [DEBUG] æœªå¤„ç†çš„äº‹ä»¶ç±»å‹: %s\n", event.Event)
				if event.Data != nil {
					if dataBytes, err := json.Marshal(event.Data); err == nil {
						fmt.Printf("äº‹ä»¶æ•°æ®: %s\n", string(dataBytes))
					}
				}
			}
		}
	}

	if err := scanner.Err(); err != nil {
		return fmt.Errorf("è¯»å–æµå¼å“åº”å¤±è´¥: %v", err)
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
	if errorMsg != "" {
		return fmt.Errorf("å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: %s", errorMsg)
	}

	// è§£æç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
	generatedText := collectedText.String()
	if generatedText == "" {
		fmt.Println("\nâš ï¸  å½“å‰APIæœªè¿”å›æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼Œä¸ç”Ÿæˆæ–‡ä»¶")
		return nil
	}

	fmt.Println("\nğŸ“ æ­£åœ¨è§£æç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹...")

	// ä¿å­˜æµ‹è¯•ç”¨ä¾‹åˆ°CSVæ–‡ä»¶
	return saveTestCasesToCSV(generatedText, format, outputFile)
}

// saveTestCasesToCSV å°†ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ä¿å­˜ä¸ºCSVæ–‡ä»¶
func saveTestCasesToCSV(generatedText, format, outputFile string) error {
	// ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
	dir := filepath.Dir(outputFile)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	// åˆ›å»ºCSVæ–‡ä»¶
	file, err := os.Create(outputFile)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤±è´¥: %v", err)
	}
	defer file.Close()

	writer := csv.NewWriter(file)
	defer writer.Flush()

	// å†™å…¥CSVå¤´éƒ¨
	if format == "xml" {
		if err := writer.Write([]string{"XML"}); err != nil {
			return fmt.Errorf("å†™å…¥CSVå¤´éƒ¨å¤±è´¥: %v", err)
		}
	} else {
		if err := writer.Write([]string{"JSON"}); err != nil {
			return fmt.Errorf("å†™å…¥CSVå¤´éƒ¨å¤±è´¥: %v", err)
		}
	}

	// è§£æç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
	testCases := parseGeneratedTestCases(generatedText, format)
	if len(testCases) == 0 {
		return fmt.Errorf("æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„æµ‹è¯•ç”¨ä¾‹")
	}

	// å†™å…¥æµ‹è¯•ç”¨ä¾‹
	for i, testCase := range testCases {
		if err := writer.Write([]string{testCase}); err != nil {
			return fmt.Errorf("å†™å…¥æµ‹è¯•ç”¨ä¾‹ %d å¤±è´¥: %v", i+1, err)
		}
	}

	fmt.Printf("ğŸ“Š æˆåŠŸè§£æå¹¶ä¿å­˜ %d ä¸ªæµ‹è¯•ç”¨ä¾‹\n", len(testCases))
	return nil
}

// maskAPIKey å®‰å…¨åœ°é®ç›–APIå¯†é’¥ï¼Œåªæ˜¾ç¤ºå‰4ä½å’Œå4ä½
func maskAPIKey(apiKey string) string {
	if len(apiKey) <= 8 {
		// å¦‚æœAPIå¯†é’¥å¤ªçŸ­ï¼Œå…¨éƒ¨ç”¨æ˜Ÿå·é®ç›–
		return strings.Repeat("*", len(apiKey))
	}
	// æ˜¾ç¤ºå‰4ä½å’Œå4ä½ï¼Œä¸­é—´ç”¨æ˜Ÿå·é®ç›–
	return apiKey[:4] + strings.Repeat("*", len(apiKey)-8) + apiKey[len(apiKey)-4:]
}

// generateUserID ç”ŸæˆåŠ¨æ€ç”¨æˆ·æ ‡è¯†ï¼šå½“å‰æ—¥æœŸæ—¶é—´+8ä½éšæœºå­—ç¬¦ä¸²
func generateUserID() string {
	// è·å–å½“å‰æ—¶é—´ï¼Œæ ¼å¼ä¸º YYYYMMDDHHMMSS
	now := time.Now()
	timeStr := now.Format("20060102150405")

	// ç”Ÿæˆ8ä½éšæœºå­—ç¬¦ä¸²
	randomStr := generateRandomString(8)

	return timeStr + randomStr
}

// generateRandomString ç”ŸæˆæŒ‡å®šé•¿åº¦çš„éšæœºå­—ç¬¦ä¸²ï¼ˆåŒ…å«å­—æ¯å’Œæ•°å­—ï¼‰
func generateRandomString(length int) string {
	const charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
	b := make([]byte, length)

	// ä½¿ç”¨crypto/randç”Ÿæˆå®‰å…¨çš„éšæœºæ•°
	if _, err := rand.Read(b); err != nil {
		// å¦‚æœcrypto/randå¤±è´¥ï¼Œä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºåå¤‡æ–¹æ¡ˆ
		fallbackStr := fmt.Sprintf("%d", time.Now().UnixNano())
		if len(fallbackStr) >= length {
			return fallbackStr[:length]
		}
		return fallbackStr + strings.Repeat("0", length-len(fallbackStr))
	}

	for i := range b {
		b[i] = charset[int(b[i])%len(charset)]
	}

	return string(b)
}

// parseGeneratedTestCases è§£æç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ–‡æœ¬
// æ”¯æŒå¤šç§æ ¼å¼ï¼š
// JSONæ ¼å¼ï¼š
//  1. JSON Arrayæ ¼å¼ï¼š[{"data_field": value1}, {"data_field": value2}]
//  2. è¿ç»­JSONå¯¹è±¡æ ¼å¼ï¼š{...} {...} {...}
//
// XMLæ ¼å¼ï¼š
//  1. è¿ç»­XMLå¯¹è±¡æ ¼å¼ï¼ŒXMLå¯¹è±¡é—´é€šè¿‡4ä¸ª$$$$ç¬¦å·åˆ†éš”ï¼š<root>...</root> <root>...</root> <root>...</root>
//
// é€šç”¨æ ¼å¼ï¼š
//  1. ä¼ ç»Ÿçš„é€è¡Œæ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
func parseGeneratedTestCases(text, format string) []string {
	var testCases []string
	seenTestCases := make(map[string]bool) // ç”¨äºå»é‡

	// JSONæ ¼å¼çš„æ™ºèƒ½è§£æ
	if format == "json" {
		// é¦–å…ˆå°è¯•è§£æJSON Arrayæ ¼å¼
		if arrayTestCases := parseJSONArrayTestCases(text); len(arrayTestCases) > 0 {
			// æˆåŠŸè§£æJSON Arrayæ ¼å¼ï¼Œè¿›è¡Œå»é‡å¤„ç†
			for _, testCase := range arrayTestCases {
				if !seenTestCases[testCase] {
					testCases = append(testCases, testCase)
					seenTestCases[testCase] = true
				}
			}
			return testCases
		}

		// å¦‚æœJSON Arrayè§£æå¤±è´¥ï¼Œå°è¯•è§£æè¿ç»­JSONå¯¹è±¡æ ¼å¼
		if consecutiveTestCases := parseConsecutiveJSONObjects(text); len(consecutiveTestCases) > 0 {
			// æˆåŠŸè§£æè¿ç»­JSONå¯¹è±¡æ ¼å¼ï¼Œè¿›è¡Œå»é‡å¤„ç†
			for _, testCase := range consecutiveTestCases {
				if !seenTestCases[testCase] {
					testCases = append(testCases, testCase)
					seenTestCases[testCase] = true
				}
			}
			return testCases
		}
	}

	// XMLæ ¼å¼çš„æ™ºèƒ½è§£æ
	if format == "xml" {
		// å°è¯•è§£æè¿ç»­XMLå¯¹è±¡æ ¼å¼
		if consecutiveTestCases := parseConsecutiveXMLObjects(text); len(consecutiveTestCases) > 0 {
			// æˆåŠŸè§£æè¿ç»­XMLå¯¹è±¡æ ¼å¼ï¼Œè¿›è¡Œå»é‡å¤„ç†
			for _, testCase := range consecutiveTestCases {
				if !seenTestCases[testCase] {
					testCases = append(testCases, testCase)
					seenTestCases[testCase] = true
				}
			}
			return testCases
		}
	}

	// å¦‚æœæ™ºèƒ½è§£æéƒ½å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„é€è¡Œè§£ææ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
	lines := strings.Split(text, "\n")
	inCodeBlock := false

	for _, line := range lines {
		line = strings.TrimSpace(line)
		// è·³è¿‡ç©ºè¡Œ
		if line == "" {
			continue
		}

		// å¤„ç†markdownä»£ç å—æ ‡è®°
		if strings.HasPrefix(line, "```") {
			inCodeBlock = !inCodeBlock
			continue
		}

		// è·³è¿‡ä»£ç å—å¤–çš„å†…å®¹
		if !inCodeBlock {
			continue
		}

		// éªŒè¯æ ¼å¼ï¼Œåªæœ‰é€šè¿‡éªŒè¯çš„è¡Œæ‰æ·»åŠ åˆ°ç»“æœä¸­
		var isValid bool
		if format == "xml" {
			isValid = ValidateXMLFormat(line) == nil
		} else {
			isValid = ValidateJSONFormat(line) == nil
		}

		// åªæœ‰æ ¼å¼éªŒè¯é€šè¿‡ä¸”æœªé‡å¤çš„è¡Œæ‰æ·»åŠ åˆ°æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
		if isValid {
			if !seenTestCases[line] {
				testCases = append(testCases, line)
				seenTestCases[line] = true
			}
		}
	}

	return testCases
}

// parseJSONArrayTestCases è§£æJSON Arrayæ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹
// è¾“å…¥æ ¼å¼ï¼š[{"data_field": value1}, {"data_field": value2}, ...]
// è¾“å‡ºï¼šæ¯ä¸ªJSONå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤º
func parseJSONArrayTestCases(text string) []string {
	var testCases []string

	// æå–JSON Arrayå†…å®¹ï¼ˆæ”¯æŒmarkdownä»£ç å—åŒ…è£…ï¼‰
	jsonArrayText := extractJSONArrayFromText(text)
	if jsonArrayText == "" {
		return testCases
	}

	// è§£æJSON Array
	var jsonArray []map[string]any
	if err := json.Unmarshal([]byte(jsonArrayText), &jsonArray); err != nil {
		// JSON Arrayè§£æå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
		return testCases
	}

	// å°†æ¯ä¸ªJSONå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
	for i, jsonObj := range jsonArray {
		if jsonBytes, err := json.Marshal(jsonObj); err == nil {
			// éªŒè¯ç”Ÿæˆçš„JSONæ ¼å¼
			jsonStr := string(jsonBytes)
			if ValidateJSONFormat(jsonStr) == nil {
				testCases = append(testCases, jsonStr)
			} else {
				fmt.Printf("âš ï¸  è·³è¿‡æ— æ•ˆçš„JSONå¯¹è±¡ %d: %s\n", i+1, jsonStr)
			}
		} else {
			fmt.Printf("âš ï¸  åºåˆ—åŒ–JSONå¯¹è±¡ %d å¤±è´¥: %v\n", i+1, err)
		}
	}

	return testCases
}

// extractJSONArrayFromText ä»æ–‡æœ¬ä¸­æå–JSON Arrayå†…å®¹
// æ”¯æŒä»markdownä»£ç å—ä¸­æå–ï¼Œä¹Ÿæ”¯æŒç›´æ¥çš„JSON Arrayæ–‡æœ¬
func extractJSONArrayFromText(text string) string {
	lines := strings.Split(text, "\n")
	inCodeBlock := false
	var jsonLines []string

	// é¦–å…ˆå°è¯•ä»markdownä»£ç å—ä¸­æå–
	for _, line := range lines {
		line = strings.TrimSpace(line)

		// å¤„ç†markdownä»£ç å—æ ‡è®°
		if strings.HasPrefix(line, "```") {
			inCodeBlock = !inCodeBlock
			continue
		}

		// æ”¶é›†ä»£ç å—å†…çš„å†…å®¹
		if inCodeBlock && line != "" {
			jsonLines = append(jsonLines, line)
		}
	}

	// å¦‚æœä»ä»£ç å—ä¸­æå–åˆ°å†…å®¹ï¼Œå°è¯•è§£æ
	if len(jsonLines) > 0 {
		jsonText := strings.Join(jsonLines, "")
		if isValidJSONArray(jsonText) {
			return jsonText
		}
	}

	// å¦‚æœä»£ç å—è§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä»æ•´ä¸ªæ–‡æœ¬ä¸­æŸ¥æ‰¾JSON Array
	cleanText := strings.TrimSpace(text)
	if isValidJSONArray(cleanText) {
		return cleanText
	}

	// å°è¯•æŸ¥æ‰¾æ–‡æœ¬ä¸­çš„JSON Arrayç‰‡æ®µ
	startIdx := strings.Index(cleanText, "[")
	endIdx := strings.LastIndex(cleanText, "]")
	if startIdx != -1 && endIdx != -1 && endIdx > startIdx {
		jsonCandidate := cleanText[startIdx : endIdx+1]
		if isValidJSONArray(jsonCandidate) {
			return jsonCandidate
		}
	}

	return ""
}

// isValidJSONArray æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæœ‰æ•ˆçš„JSON Array
func isValidJSONArray(text string) bool {
	var jsonArray []any
	return json.Unmarshal([]byte(text), &jsonArray) == nil
}

// parseConsecutiveJSONObjects è§£æè¿ç»­JSONå¯¹è±¡æ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹
// è¾“å…¥æ ¼å¼ï¼š{"name": "å¼ ä¸‰"} {"name": "æå››"} ...
// è¾“å‡ºï¼šæ¯ä¸ªJSONå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤º
func parseConsecutiveJSONObjects(text string) []string {
	var testCases []string

	// æå–è¿ç»­JSONå¯¹è±¡å†…å®¹ï¼ˆæ”¯æŒmarkdownä»£ç å—åŒ…è£…ï¼‰
	jsonObjectsText := extractConsecutiveJSONFromText(text)
	if jsonObjectsText == "" {
		return testCases
	}

	// è§£æè¿ç»­çš„JSONå¯¹è±¡
	jsonObjects := splitConsecutiveJSONObjects(jsonObjectsText)

	// éªŒè¯å¹¶æ·»åŠ æ¯ä¸ªJSONå¯¹è±¡
	for i, jsonStr := range jsonObjects {
		jsonStr = strings.TrimSpace(jsonStr)
		if jsonStr == "" {
			continue
		}

		// éªŒè¯JSONæ ¼å¼
		if ValidateJSONFormat(jsonStr) == nil {
			testCases = append(testCases, jsonStr)
		} else {
			fmt.Printf("âš ï¸  è·³è¿‡æ— æ•ˆçš„JSONå¯¹è±¡ %d: %s\n", i+1, jsonStr)
		}
	}

	return testCases
}

// extractConsecutiveJSONFromText ä»æ–‡æœ¬ä¸­æå–è¿ç»­JSONå¯¹è±¡å†…å®¹
// æ”¯æŒä»markdownä»£ç å—ä¸­æå–ï¼Œä¹Ÿæ”¯æŒç›´æ¥çš„è¿ç»­JSONå¯¹è±¡æ–‡æœ¬
func extractConsecutiveJSONFromText(text string) string {
	lines := strings.Split(text, "\n")
	inCodeBlock := false
	var jsonLines []string

	// é¦–å…ˆå°è¯•ä»markdownä»£ç å—ä¸­æå–
	for _, line := range lines {
		line = strings.TrimSpace(line)

		// å¤„ç†markdownä»£ç å—æ ‡è®°
		if strings.HasPrefix(line, "```") {
			inCodeBlock = !inCodeBlock
			continue
		}

		// æ”¶é›†ä»£ç å—å†…çš„å†…å®¹
		if inCodeBlock && line != "" {
			jsonLines = append(jsonLines, line)
		}
	}

	// å¦‚æœä»ä»£ç å—ä¸­æå–åˆ°å†…å®¹ï¼Œè¿”å›åˆå¹¶çš„æ–‡æœ¬
	if len(jsonLines) > 0 {
		jsonText := strings.Join(jsonLines, " ")
		if containsConsecutiveJSONObjects(jsonText) {
			return jsonText
		}
	}

	// å¦‚æœä»£ç å—è§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä»æ•´ä¸ªæ–‡æœ¬ä¸­æŸ¥æ‰¾è¿ç»­JSONå¯¹è±¡
	cleanText := strings.TrimSpace(text)
	if containsConsecutiveJSONObjects(cleanText) {
		return cleanText
	}

	return ""
}

// splitConsecutiveJSONObjects åˆ†å‰²è¿ç»­çš„JSONå¯¹è±¡
// ä½¿ç”¨ç®€å•çš„å¤§æ‹¬å·åŒ¹é…æ¥åˆ†å‰²JSONå¯¹è±¡
func splitConsecutiveJSONObjects(text string) []string {
	var jsonObjects []string
	var currentObject strings.Builder
	braceCount := 0
	inString := false
	escaped := false

	for _, char := range text {
		if escaped {
			escaped = false
			currentObject.WriteRune(char)
			continue
		}

		if char == '\\' {
			escaped = true
			currentObject.WriteRune(char)
			continue
		}

		if char == '"' {
			inString = !inString
			currentObject.WriteRune(char)
			continue
		}

		if !inString {
			if char == '{' {
				braceCount++
				currentObject.WriteRune(char)
			} else if char == '}' {
				braceCount--
				currentObject.WriteRune(char)

				// å½“å¤§æ‹¬å·åŒ¹é…å®Œæˆæ—¶ï¼Œè¡¨ç¤ºä¸€ä¸ªJSONå¯¹è±¡ç»“æŸ
				if braceCount == 0 {
					jsonObj := strings.TrimSpace(currentObject.String())
					if jsonObj != "" {
						jsonObjects = append(jsonObjects, jsonObj)
					}
					currentObject.Reset()
				}
			} else if braceCount > 0 {
				// åªæœ‰åœ¨JSONå¯¹è±¡å†…éƒ¨æ—¶æ‰æ·»åŠ å­—ç¬¦
				currentObject.WriteRune(char)
			}
			// å¿½ç•¥JSONå¯¹è±¡å¤–éƒ¨çš„ç©ºç™½å­—ç¬¦
		} else {
			// åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼Œæ·»åŠ æ‰€æœ‰å­—ç¬¦
			currentObject.WriteRune(char)
		}
	}

	return jsonObjects
}

// containsConsecutiveJSONObjects æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«è¿ç»­çš„JSONå¯¹è±¡
// ç®€å•æ£€æŸ¥ï¼šè‡³å°‘åŒ…å«ä¸¤ä¸ªç‹¬ç«‹çš„JSONå¯¹è±¡ï¼ˆä»¥}å¼€å¤´çš„{ç»“å°¾ï¼‰
func containsConsecutiveJSONObjects(text string) bool {
	// ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦è¿›è¡Œç®€å•æ£€æŸ¥
	cleanText := strings.ReplaceAll(text, " ", "")
	cleanText = strings.ReplaceAll(cleanText, "\n", "")
	cleanText = strings.ReplaceAll(cleanText, "\t", "")

	// æ£€æŸ¥æ˜¯å¦åŒ…å«è‡³å°‘ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡æ¨¡å¼
	// ç®€å•æ¨¡å¼ï¼š}{ è¡¨ç¤ºä¸¤ä¸ªè¿ç»­çš„JSONå¯¹è±¡
	return strings.Contains(cleanText, "}{")
}

// parseConsecutiveXMLObjects è§£æè¿ç»­XMLå¯¹è±¡æ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹
// è¾“å…¥æ ¼å¼ï¼š<user><name>å¼ ä¸‰</name></user>$$$$<user><name>æå››</name></user>$$$$
// è¾“å‡ºï¼šæ¯ä¸ªXMLå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤º
func parseConsecutiveXMLObjects(text string) []string {
	var testCases []string

	// æå–è¿ç»­XMLå¯¹è±¡å†…å®¹ï¼ˆæ”¯æŒmarkdownä»£ç å—åŒ…è£…ï¼‰
	xmlObjectsText := extractConsecutiveXMLFromText(text)
	if xmlObjectsText == "" {
		return testCases
	}

	// è§£æä½¿ç”¨$$$$åˆ†éš”çš„XMLå¯¹è±¡
	xmlObjects := splitXMLObjectsByDelimiter(xmlObjectsText)

	// éªŒè¯å¹¶æ·»åŠ æ¯ä¸ªXMLå¯¹è±¡
	for i, xmlStr := range xmlObjects {
		xmlStr = strings.TrimSpace(xmlStr)
		if xmlStr == "" {
			continue
		}

		// éªŒè¯XMLæ ¼å¼
		if ValidateXMLFormat(xmlStr) == nil {
			testCases = append(testCases, xmlStr)
		} else {
			fmt.Printf("âš ï¸  è·³è¿‡æ— æ•ˆçš„XMLå¯¹è±¡ %d: %s\n", i+1, xmlStr)
		}
	}

	return testCases
}

// extractConsecutiveXMLFromText ä»æ–‡æœ¬ä¸­æå–è¿ç»­XMLå¯¹è±¡å†…å®¹
// æ”¯æŒä»markdownä»£ç å—ä¸­æå–ï¼Œä¹Ÿæ”¯æŒç›´æ¥çš„è¿ç»­XMLå¯¹è±¡æ–‡æœ¬
func extractConsecutiveXMLFromText(text string) string {
	lines := strings.Split(text, "\n")
	inCodeBlock := false
	var xmlLines []string

	// é¦–å…ˆå°è¯•ä»markdownä»£ç å—ä¸­æå–
	for _, line := range lines {
		line = strings.TrimSpace(line)

		// å¤„ç†markdownä»£ç å—æ ‡è®°
		if strings.HasPrefix(line, "```") {
			inCodeBlock = !inCodeBlock
			continue
		}

		// æ”¶é›†ä»£ç å—å†…çš„å†…å®¹
		if inCodeBlock && line != "" {
			xmlLines = append(xmlLines, line)
		}
	}

	// å¦‚æœä»ä»£ç å—ä¸­æå–åˆ°å†…å®¹ï¼Œè¿”å›åˆå¹¶çš„æ–‡æœ¬
	if len(xmlLines) > 0 {
		xmlText := strings.Join(xmlLines, " ")
		if containsXMLWithDelimiter(xmlText) {
			return xmlText
		}
	}

	// å¦‚æœä»£ç å—è§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä»æ•´ä¸ªæ–‡æœ¬ä¸­æŸ¥æ‰¾è¿ç»­XMLå¯¹è±¡
	cleanText := strings.TrimSpace(text)
	if containsXMLWithDelimiter(cleanText) {
		return cleanText
	}

	return ""
}

// splitXMLObjectsByDelimiter ä½¿ç”¨$$$$åˆ†éš”ç¬¦åˆ†å‰²XMLå¯¹è±¡
// è¾“å…¥æ ¼å¼ï¼š<xml1>...</xml1>$$$$<xml2>...</xml2>$$$$
// è¾“å‡ºï¼šæ¯ä¸ªXMLå¯¹è±¡çš„å­—ç¬¦ä¸²æ•°ç»„
func splitXMLObjectsByDelimiter(text string) []string {
	var xmlObjects []string

	// ä½¿ç”¨$$$$ä½œä¸ºåˆ†éš”ç¬¦åˆ†å‰²æ–‡æœ¬
	delimiter := "$$$$"
	// ä½¿ç”¨SplitAfteræ›´é«˜æ•ˆåœ°åˆ†å‰²æ–‡æœ¬
	parts := strings.SplitAfter(text, delimiter)

	// å¤„ç†æ¯ä¸ªåˆ†å‰²åçš„éƒ¨åˆ†
	for _, part := range parts {
		part = strings.TrimSpace(part)
		if part != "" {
			xmlObjects = append(xmlObjects, part)
		}
	}

	// å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†éš”ç¬¦ï¼Œä½†æ–‡æœ¬åŒ…å«XMLå†…å®¹ï¼Œåˆ™å°†æ•´ä¸ªæ–‡æœ¬ä½œä¸ºå•ä¸ªXMLå¯¹è±¡
	if len(xmlObjects) == 1 && xmlObjects[0] == strings.TrimSpace(text) {
		// æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯å•ä¸ªXMLå¯¹è±¡
		if strings.Contains(text, "<") && strings.Contains(text, ">") {
			return xmlObjects
		}
		return []string{}
	}

	return xmlObjects
}

// containsXMLWithDelimiter æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä½¿ç”¨$$$$åˆ†éš”çš„XMLå¯¹è±¡
// æˆ–è€…åŒ…å«å•ä¸ªXMLå¯¹è±¡
func containsXMLWithDelimiter(text string) bool {
	// æ£€æŸ¥æ˜¯å¦åŒ…å«$$$$åˆ†éš”ç¬¦
	if strings.Contains(text, "$$$$") {
		return true
	}

	// æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬çš„XMLç»“æ„
	if strings.Contains(text, "<") && strings.Contains(text, ">") {
		return true
	}

	return false
}
